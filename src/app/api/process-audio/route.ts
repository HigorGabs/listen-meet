import { NextRequest, NextResponse } from 'next/server'
import { GoogleGenerativeAI } from '@google/generative-ai'

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const audioFile = formData.get('audio') as File
    const apiKey = formData.get('apiKey') as string
    const duration = parseInt(formData.get('duration') as string)

    if (!apiKey) {
      return NextResponse.json({ error: 'API Key √© obrigat√≥ria' }, { status: 400 })
    }

    if (!audioFile) {
      return NextResponse.json({ error: 'Arquivo de √°udio √© obrigat√≥rio' }, { status: 400 })
    }

    console.log('Processing audio file:', audioFile.name, audioFile.size, 'bytes')

    // Convert audio file to base64
    const audioBuffer = await audioFile.arrayBuffer()
    const audioBase64 = Buffer.from(audioBuffer).toString('base64')

    // Process with Gemini
    const genAI = new GoogleGenerativeAI(apiKey)
    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' })

    const prompt = `
Analise o seguinte arquivo de √°udio de uma reuni√£o e gere um resumo estruturado.

DURA√á√ÉO: ${Math.floor(duration / 60)} minutos

Por favor, forne√ßa um resumo estruturado no seguinte formato JSON:

{
  "title": "T√≠tulo sugerido para a reuni√£o",
  "overview": "Resumo geral da reuni√£o em 2-3 par√°grafos",
  "summary": "Par√°grafo conciso de 2-3 linhas explicando o contexto geral da reuni√£o, principais decis√µes tomadas e pr√≥ximos passos definidos",
  "keyPoints": ["Ponto principal 1", "Ponto principal 2", "Ponto principal 3"],
  "actionItems": ["A√ß√£o 1", "A√ß√£o 2", "A√ß√£o 3"],
  "participants": ["Participante 1", "Participante 2"],
  "topics": ["T√≥pico 1", "T√≥pico 2", "T√≥pico 3"],
  "metrics": {
    "efficiency": "75%",
    "engagement": "Alto",
    "decisionsCount": 3
  },
  "timeline": [
    {"phase": "In√≠cio", "description": "Apresenta√ß√£o do t√≥pico", "time": "0-5min"},
    {"phase": "Discuss√£o principal", "description": "An√°lise detalhada", "time": "5-20min"},
    {"phase": "Decis√µes", "description": "Defini√ß√£o de a√ß√µes", "time": "20-25min"}
  ],
  "tags": {
    "meetingType": "Planejamento",
    "priority": "Alta",
    "status": "Conclu√≠da"
  },
  "insights": {
    "sentiment": "Produtiva",
    "engagement": "Alto",
    "outcome": "Decis√µes claras"
  },
  "participationAnalysis": [
    {"participant": "Participante A", "talkTime": "40%", "contributions": "Ideias t√©cnicas", "role": "Facilitador"},
    {"participant": "Participante B", "talkTime": "35%", "contributions": "An√°lise de mercado", "role": "Especialista"},
    {"participant": "Participante C", "talkTime": "25%", "contributions": "Quest√µes pr√°ticas", "role": "Questionador"}
  ],
  "transcript": "Transcri√ß√£o completa do √°udio"
}

INSTRU√á√ïES:
- Transcreva o √°udio completo para texto
- Identifique os pontos mais importantes da discuss√£o
- Extraia todas as a√ß√µes espec√≠ficas mencionadas
- Liste os participantes identific√°veis na conversa
- Categorize os principais t√≥picos abordados
- Analise a efici√™ncia da reuni√£o (% de tempo produtivo vs tangencial)
- Avalie o n√≠vel de engajamento dos participantes
- Conte quantas decis√µes concretas foram tomadas
- Crie uma timeline simples das fases da reuni√£o
- Categorize o tipo de reuni√£o (Planejamento, Review, Brainstorm, Status)
- Defina prioridade (Alta, M√©dia, Baixa) baseada na urg√™ncia dos t√≥picos
- Analise o sentimento geral (Produtiva, Construtiva, Tensa)
- Avalie se houve decis√µes claras ou se precisa follow-up
- Distribua tempo de fala por participante (aproximado)
- Identifique principais contribui√ß√µes de cada um
- Use portugu√™s brasileiro
- Seja conciso mas abrangente
- Se n√£o conseguir identificar participantes espec√≠ficos, use "Participante A", "Participante B", etc.

Responda APENAS com o JSON v√°lido, sem texto adicional.
`

    console.log('Sending audio to Gemini for processing...')
    
    const result = await model.generateContent([
      {
        inlineData: {
          mimeType: audioFile.type,
          data: audioBase64
        }
      },
      { text: prompt }
    ])

    const response = await result.response
    const text = response.text()

    console.log('Raw Gemini response:', text.substring(0, 500) + '...')

    // Try to extract JSON from response
    const jsonMatch = text.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('No JSON found in Gemini response')
    }

    const summary = JSON.parse(jsonMatch[0])

    // Validate structure
    if (!summary.title || !summary.overview || !Array.isArray(summary.keyPoints)) {
      throw new Error('Invalid summary structure from Gemini')
    }

    console.log('Audio processing completed successfully')

    // Generate filename for download
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const filename = `reuniao-${timestamp}.txt`

    // Create downloadable content
    const downloadContent = `RESUMO DA REUNI√ÉO - ${summary.title}
Data: ${new Date().toLocaleDateString('pt-BR')}
Dura√ß√£o: ${Math.floor(duration / 60)} minutos

=== RESUMO ===
${summary.summary || summary.overview}

=== RESUMO GERAL ===
${summary.overview}

=== üìä M√âTRICAS DA REUNI√ÉO ===
Efici√™ncia: ${summary.metrics?.efficiency || 'N/A'}
Participa√ß√£o: ${summary.metrics?.engagement || 'N/A'}
Decis√µes tomadas: ${summary.metrics?.decisionsCount || 'N/A'}

=== ‚è∞ TIMELINE DA REUNI√ÉO ===
${summary.timeline?.map((item: { phase: string; description: string; time: string }) => `${item.phase}: ${item.description} (${item.time})`).join('\n') || 'Timeline n√£o dispon√≠vel'}

=== üè∑Ô∏è TAGS/CATEGORIAS ===
Tipo de reuni√£o: ${summary.tags?.meetingType || 'N/A'}
Prioridade: ${summary.tags?.priority || 'N/A'}
Status: ${summary.tags?.status || 'N/A'}

=== üìà INSIGHTS DA IA ===
Sentiment: ${summary.insights?.sentiment || 'N/A'}
Engagement: ${summary.insights?.engagement || 'N/A'}
Outcome: ${summary.insights?.outcome || 'N/A'}

=== üë• AN√ÅLISE DE PARTICIPA√á√ÉO ===
${summary.participationAnalysis?.map((p: { participant: string; talkTime: string; contributions: string; role: string }) => 
  `${p.participant}: ${p.talkTime} do tempo | ${p.contributions} | Papel: ${p.role}`
).join('\n') || 'An√°lise n√£o dispon√≠vel'}

=== PONTOS PRINCIPAIS ===
${summary.keyPoints.map((point: string, index: number) => `${index + 1}. ${point}`).join('\n')}

=== A√á√ïES IDENTIFICADAS ===
${summary.actionItems.map((action: string, index: number) => `${index + 1}. ${action}`).join('\n')}

=== PARTICIPANTES ===
${summary.participants.join(', ')}

=== T√ìPICOS ABORDADOS ===
${summary.topics.join(', ')}

=== TRANSCRI√á√ÉO COMPLETA ===
${summary.transcript || 'Transcri√ß√£o n√£o dispon√≠vel'}

---
Gerado automaticamente pelo Listen Meet com Google Gemini AI
`

    return NextResponse.json({
      success: true,
      summary,
      filename,
      downloadContent,
      duration
    })

  } catch (error: unknown) {
    console.error('Error processing audio:', error)
    
    return NextResponse.json({
      error: 'Erro ao processar √°udio: ' + (error instanceof Error ? error.message : 'Erro desconhecido'),
      fallback: true
    }, { status: 500 })
  }
}